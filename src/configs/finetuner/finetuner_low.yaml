config:
    # IDs & paths
    data_id: "exp_not_norm"
    model_id: "finetuner_not_norm_low"
    models_dir: "../trained_models/exp_not_norm"

    # Training params
    source: "generator_low"
    network_type: "low"
    iterations: 400
    num_classes: 72
    sigmoid_params: [500,150]
    batch_size: 500
    lr: 0.001

    # WANDB params
    enable_logging: True
    wandb_project_id: "finetuner_generator_not_norm"

    # Network params
    num_hidden_layers: 3
    num_neurons: 60

    # Misc
    device: "cuda"